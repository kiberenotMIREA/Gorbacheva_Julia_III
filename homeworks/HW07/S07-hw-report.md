# HW07 – Report

> Файл: `homeworks/HW07/report.md`
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

- `S07-hw-dataset-01.csv` (Dataset A)
- `S07-hw-dataset-02.csv` (Dataset B)
- `S07-hw-dataset-03.csv` (Dataset C)

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000 строк, 9 столбцов)
- Признаки: числовые (f01, f02, f03, f04, f05, f06, f07, f08)
- Пропуски: нет
- "Подлости" датасета: признаки в разных шкалах (требуется масштабирование)

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000 строк, 4 столбца)
- Признаки: числовые (x1, x2, z_noise)
- Пропуски: нет
- "Подлости" датасета: нелинейная структура, выбросы (z_noise), лишний шумовой признак

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000 строк, 5 столбцов)
- Признаки: числовые (x1, x2, f_corr, f_noise)
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности, фоновый шум

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- **Препроцессинг:** для всех датасетов применялось масштабирование `StandardScaler` для нормализации признаков.
- **Поиск гиперпараметров:**
  - **KMeans:** перебор `k` в диапазоне от 2 до 20.
  - **DBSCAN:** перебор `eps` (например, [0.3, 0.4, 0.5]) и `min_samples` (например, [3, 4, 5]).
  - **AgglomerativeClustering:** перебор `k` от 2 до 10 и `linkage` ('ward', 'complete', 'average').
  - **Руководствовались** метрикой `silhouette_score` как основным критерием при выборе "лучшего" решения, но учитывали и `davies_bouldin_score`, и `calinski_harabasz_score`.
- **Метрики:** `silhouette_score`, `davies_bouldin_score`, `calinski_harabasz_score`. Для DBSCAN метрики вычислялись на `non-noise` точках (точки с меткой -1 исключались).
- **Визуализация:** использовалась проекция `PCA(2D)` для визуализации кластеров. Графики `silhouette vs k` и `silhouette vs eps` строились для подбора гиперпараметров.

## 3. Models

Минимум (для каждого датасета):

- KMeans (поиск `k`, фиксировали `random_state=42`, `n_init=10`)
- Один из:
  - **Dataset A:** DBSCAN (`eps`, `min_samples`)
  - **Dataset B:** AgglomerativeClustering (`k`, `linkage`)
  - **Dataset C:** DBSCAN (`eps`, `min_samples`)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- **Лучший метод и параметры:** KMeans, k=2
- **Метрики (silhouette / DB / CH):** 0.5216 / 0.6853 / 11786.9546
- **Если был DBSCAN:** Silhouette (non-noise)=0.3816, DBI=1.2518, CHI=8432.6925, доля шума не указана.
- **Коротко:** KMeans показал лучшие метрики, что говорит о сферических и относительно однородных кластерах, подходящих для этого метода после масштабирования.

### 4.2 Dataset B

- **Лучший метод и параметры:** AgglomerativeClustering, k=2, linkage='average'
- **Метрики (silhouette / DB / CH):** 0.4198 / 0.8791 / 395.4826
- **Если был DBSCAN:** (не применялся)
- **Коротко:** AgglomerativeClustering оказался более подходящим для нелинейной структуры данных, показав лучший `silhouette` по сравнению с KMeans.

### 4.3 Dataset C

- **Лучший метод и параметры:** KMeans, k=3
- **Метрики (silhouette / DB / CH):** 0.3155 / 1.1577 / 6957.1626
- **Если был DBSCAN:** Silhouette (non-noise)=0.1855, DBI=1.1420, CHI=3132.7543, доля шума не указана.
- **Коротко:** Несмотря на ожидаемое преимущество DBSCAN для кластеров разной плотности, KMeans показал лучший `silhouette` и `CHI`, возможно, из-за специфики структуры данных или параметров DBSCAN.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **Где KMeans "ломается" и почему?** KMeans плохо справляется с несферическими кластерами (второй датасет) и кластерами разной плотности (третий датасет), так как он опирается на средние расстояния до центроидов.
- **Где DBSCAN/иерархическая кластеризация выигрывают и почему?** DBSCAN эффективен при наличии шума и кластеров произвольной формы/плотности (третий датасет, хотя в этом случае он не выиграл). Иерархическая кластеризация (Agglomerative) может лучше справляться с нелинейными структурами (второй датасет).
- **Что сильнее всего влияло на результат?** Масштабирование признаков было критически важным для всех методов. Наличие выбросов и шума влияло на интерпретацию результатов и выбор метода (например, второй и третий датасет).

### 5.2 Устойчивость (обязательно для одного датасета)

- **Какую проверку устойчивости делали:** 5 запусков KMeans с `random_state` от 42 до 46 и фиксированным `n_init=10` на первый датасет. Сравнивались результаты с помощью `Adjusted Rand Index (ARI)`.
- **Что получилось:** Средний ARI между запусками был близок к 1.0, что указывает на высокую стабильность решения KMeans при фиксированных параметрах.
- **Вывод:** Решение KMeans для первого датасета является устойчивым, так как оно воспроизводимо при разных `random_state`. Это говорит о том, что алгоритм стабильно находит схожие кластеры на этом датасете при разных начальных условиях. Низкий разброс в метриках и результатах кластеризации подтверждает надёжность выбранного метода и параметров. Такая устойчивость важна для доверия к полученным результатам и их воспроизводимости.

### 5.3 Интерпретация кластеров

- **Как вы интерпретировали кластеры:** В рамках задания интерпретация кластеров в виде профилей признаков (средние/медианы по кластерам) не проводилась. Визуализация с помощью PCA(2D) использовалась для оценки формы и распределения кластеров.
- **3-6 строк выводов:** Визуализация показала, что для первого датасета кластеры были относительно чётко разделены. Для второго датасета структура была сложнее, что повлияло на выбор метода. Для третьего датасета визуализация могла бы помочь понять, почему DBSCAN не оказался лучшим, несмотря на ожидания. PCA-визуализация помогает визуально оценить, насколько чётко алгоритм разделил данные. Интерпретация кластеров важна для понимания, какие особенности данных определяют принадлежность к группе. Без дополнительных аналитических инструментов (например, анализа центроидов или распределений признаков по кластерам) интерпретация остаётся поверхностной.

## 6. Conclusion

- Масштабирование признаков критически важно для корректной работы алгоритмов кластеризации.
- Выбор метрики (silhouette, DBI, CHI) влияет на оценку качества, и желательно использовать несколько метрик для комплексного анализа.
- KMeans эффективен для сферических кластеров, но чувствителен к структуре данных.
- DBSCAN и AgglomerativeClustering более гибкие, но требуют тщательного подбора параметров.
- Проверка устойчивости модели важна для оценки надёжности результата.
- Визуализация (PCA) помогает интерпретировать структуру данных и результаты кластеризации.
