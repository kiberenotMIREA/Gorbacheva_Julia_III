# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-04.csv` (датасет с сильным дисбалансом)
- Размер: (2500, 62) - 2500 строк, 62 столбца (60 признаков f01-f60 + id + target)
- Целевая переменная: `target` (классы 0 и 1, сильный дисбаланс — класс 0 составляет 95.08%, класс 1 — 4.92%)
- Признаки: числовые признаки (f01-f60), все непрерывные, без явно категориальных

## 2. Protocol

- Разбиение: train/test (80/20, random_state=42, stratify=y) — для сохранения пропорций классов в обеих выборках
- Подбор: 5-фолдная CV на train (GridSearchCV), оптимизировали по ROC-AUC — наиболее уместная метрика для задач с дисбалансом
- Метрики: accuracy, F1, ROC-AUC 
    - accuracy: общая точность, но может быть обманчива при дисбалансе;
    - F1: гармоническое среднее precision и recall, учитывает оба класса;
    - ROC-AUC: площадь под ROC-кривой — показывает способность модели различать классы, устойчива к дисбалансу

## 3. Models

Сравнивали следующие модели:
- DummyClassifier (baseline) - стратегия most_frequent (предсказывает самый частый класс)
- LogisticRegression (baseline из S05) - Pipeline с StandardScaler для нормализации признаков
- DecisionTreeClassifier (контроль сложности: max_depth=[5,7,10,15], min_samples_leaf=[25,50,100]) — чтобы избежать переобучения
- RandomForestClassifier (n_estimators=[50,100,200], max_depth=[5,10,15],min_samples_leaf=[5,10,15], max_features=['sqrt','log2', 0.8]) — ансамбль деревьев с рандомизацией признаков
- GradientBoostingClassifier (n_estimators=[100,200], max_depth=[4,6,8], learning_rate=[0.05,0.1,0.15], learning_rate=[25,50]) — последовательное улучшение модели

## 4. Results
Таблица финальных метрик на test по всем моделям

| Model | Accuracy | F1 | ROC-AUC |
|-------|----------|----|---------|
| Dummy | 0.951 | 0.000 | 0.500 |
| Logistic Regression | 0.963 | 0.413 | 0.840 |
| Decision Tree | 0.962 | 0.486 | 0.832 |
| Random Forest | 0.973 | 0.633 | 0.899 |
| Gradient Boosting | 0.980 | 0.754 | 0.904 |

- Победитель: Gradient Boosting (ROC-AUC = 0.904) - показал лучшее качество на задаче с дисбалансом


## 5. Analysis

- Устойчивость: 
    - при изменении random_state модель RandomForestClassifier показывает стабильные результаты — стандартное отклонение ROC-AUC по 5 прогонам составляет 0.009. Это указывает на то, что модель не сильно зависит от случайного разбиения данных и демонстрирует хорошую воспроизводимость.
    - при изменении random_state модель DecisionTreeClassifier показывает умеренную стабильность — стандартное отклонение ROC-AUC по 5 прогонам составляет 0.023. Это указывает на то, что качество модели может заметно меняться в зависимости от случайного разбиения данных, что требует осторожности при интерпретации результатов.
- Ошибки: confusion matrix для лучшей модели (Gradient Boosting) показывает, что модель делает **очень мало ложноположительных ошибок (FP = 2)**, но **относительно много ложноотрицательных (FN = 120)**. В задачах fraud detection это означает, что модель консервативна — она редко ошибается, называя легальные операции мошенничеством, но при этом пропускает значительную часть реальных мошенничеств. Поскольку FN (пропущенные мошенничества) обычно дороже FP (ложные срабатывания), этот баланс следует рассматривать как компромисс, который можно оптимизировать через порог вероятности или метрику F1.
- Интерпретация: permutation importance показывает, что признаки **f58, f25, f53** являются наиболее важными для предсказаний модели — они оказывают наибольшее влияние на качество. Наиболее значимый признак `f58` имеет среднюю важность 0.011168, что значительно превышает остальные. Это указывает на то, что именно этот признак содержит ключевую информацию для различения классов в задаче fraud detection. Остальные топ-10 признаков (f25, f53, f38, f47 и др.) также вносят вклад, но менее существенный. Такая интерпретация помогает понять, какие признаки действительно критичны для работы модели и могут быть использованы для дальнейшего анализа или отбора признаков.

## 6. Conclusion

- Деревья решений склонны к переобучению без контроля сложности, что подтверждается более низким качеством по сравнению с ансамблями. Параметры max_depth и min_samples_leaf критически важны для предотвращения переобучения.
- Ансамблевые методы (Random Forest и Gradient Boosting) значительно превосходят одиночные деревья и baseline-модели, особенно на задачах с дисбалансом классов, где важна способность модели обобщать и устойчиво работать с редкими положительными примерами.
- Для задач с сильным дисбалансом (dataset-04) метрики accuracy недостаточно — необходимо использовать F1 и ROC-AUC, которые лучше отражают качество на несбалансированных данных. ROC-AUC особенно важен для оценки способности модели различать классы.
- Честный ML-эксперимент требует фиксированного train/test разбиения, подбора гиперпараметров только на train через кросс-валидацию и единых метрик для сравнения моделей. Это обеспечивает объективную оценку и воспроизводимость результатов.
- Подбор гиперпараметров через GridSearchCV помогает избежать переобучения на параметрах и позволяет выбрать оптимальные значения для каждой модели. Использование CV на train предотвращает оптимистичные оценки.
- Интерпретация моделей через permutation importance позволяет понять, какие признаки действительно влияют на решения модели. В нашем случае признаки f58, f25, f53 оказались наиболее важными, что может быть связано с доменной логикой задачи fraud detection.
- Модель DecisionTreeClassifier показывает умеренную чувствительность к случайным разбиениям данных (std ROC-AUC = 0.023), что требует осторожности при интерпретации результатов и необходимости усреднения по нескольким запускам при сравнении моделей.
